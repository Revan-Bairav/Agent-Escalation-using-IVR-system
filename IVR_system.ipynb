{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjzKAlcKgfAJ",
        "outputId": "1558de47-d7a3-4724-d4bc-f60b03996a35"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the model (adjust the path as necessary)\n",
        "model_path = '/content/drive/My Drive/BERT_SurveySparrow_Model'\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "device = torch.device('cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZZmiQPbrQ7Z",
        "outputId": "004bdbba-bf3d-4f3e-fda0-22d1c0b8163d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(query):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    sentiment_score = probabilities[0][1].item()  # Probability of positive sentiment\n",
        "\n",
        "    if sentiment_score > 0.6:\n",
        "        return \"Positive\"\n",
        "    elif sentiment_score < 0.4:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "def extract_keywords(query, num_keywords=5):\n",
        "    tokens = word_tokenize(query.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and token.isalnum()]\n",
        "    fdist = FreqDist(tokens)\n",
        "    return [word for word, _ in fdist.most_common(num_keywords)]\n",
        "\n",
        "def analyze_query(query):\n",
        "    sentiment = predict_sentiment(query)\n",
        "    keywords = extract_keywords(query)\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"sentiment\": sentiment,\n",
        "        \"keywords\": keywords\n",
        "    }"
      ],
      "metadata": {
        "id": "nuxFqRNfsSyo"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(analysis_result):\n",
        "    sentiment = analysis_result['sentiment']\n",
        "    keywords = analysis_result['keywords']\n",
        "\n",
        "    if sentiment == \"Negative\":\n",
        "        return \"I'm sorry to hear that you're having difficulties. Let me connect you with a specialist who can help you right away.\", True\n",
        "    elif \"password\" in keywords:\n",
        "        return \"To reset your password, please go to the login page and click on 'Forgot Password'.\", False\n",
        "    elif \"survey\" in keywords and \"create\" in keywords:\n",
        "        return \"Creating a new survey is easy! Just log in to your account and click on 'Create New Survey' on the dashboard.\", False\n",
        "    else:\n",
        "        return \"Thank you for your query. How else can I assist you today?\", False\n"
      ],
      "metadata": {
        "id": "doc6S2CcsaB3"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Welcome to Simple Workspace!\")\n",
        "    print(\"Type your query or type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"Your query: \")\n",
        "\n",
        "        if query.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        analysis_result = analyze_query(query)\n",
        "        response, should_escalate = generate_response(analysis_result)\n",
        "\n",
        "        print(\"Response:\", response)\n",
        "        if should_escalate:\n",
        "            print(\"Escalating call...\")\n",
        "        else:\n",
        "            print(\"Not escalating call.\")\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v8F4kQ26h2P",
        "outputId": "134aa08c-8419-4909-d6e6-d5def76244bc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Simple Workspace!\n",
            "Type your query or type 'exit' to quit.\n",
            "Your query: I forgot my password. is this bad?\n",
            "Response: To reset your password, please go to the login page and click on 'Forgot Password'.\n",
            "Not escalating call.\n",
            "\n",
            "Your query: exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IVR using Speech to text\n"
      ],
      "metadata": {
        "id": "_PtAvU3y6bYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "def audio_to_text(file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        text = recognizer.recognize_google(audio_data)"
      ],
      "metadata": {
        "id": "Q17RrQ6L4omW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def process_audio_file(file_path):\n",
        "    text = audio_to_text(file_path)\n",
        "    sentiment = predict_sentiment(text)\n",
        "\n",
        "    if sentiment == \"Negative\":\n",
        "        return \"I'm sorry to hear that you're having difficulties. Let me connect you with a specialist who can help you right away.\", True\n",
        "    else:\n",
        "        return \"Thank you for your query. How else can I assist you today?\", False\n"
      ],
      "metadata": {
        "id": "tjbt7MhZ4rD-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    audio_file_path = '/content/record_out.wav'\n",
        "    recognized_text = audio_to_text(audio_file_path)\n",
        "    print(\"Recognized Text:\", recognized_text)\n",
        "\n",
        "    # Further processing with sentiment analysis or other logic\n",
        "    sentiment = predict_sentiment(recognized_text)\n",
        "\n",
        "    if sentiment == \"Negative\":\n",
        "        print(\"Sentiment: Negative\")\n",
        "        print(\"I'm sorry to hear that you're having difficulties. Let me connect you with a specialist who can help you right away.\")\n",
        "        print(\"Escalating call...\")\n",
        "    else:\n",
        "        print(\"Sentiment: Positive or Neutral\")\n",
        "        print(\"Thank you for your query. How else can I assist you today?\")\n",
        "        print(\"Not escalating call.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uCdxVBI4v1G",
        "outputId": "d63bc194-0e55-44f8-911c-d3f0b97d38b9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted text: the service is too bad\n",
            "Recognized Text: the service is too bad\n",
            "Sentiment: Positive or Neutral\n",
            "Thank you for your query. How else can I assist you today?\n",
            "Not escalating call.\n"
          ]
        }
      ]
    }
  ]
}