{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ZhVLHMBC3YK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7958d9e8-0ebd-4de2-db4d-e4863c56d988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8xqCD3IEaqO",
        "outputId": "5a0e60f9-ef39-406d-b0e1-796bdcdb7773"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model and tokenizer\n",
        "import os\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "model_path = '/content/drive/My Drive/BERT_SurveySparrow_Model'\n",
        "config = BertConfig.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, config=config)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "def predict_sentiment(query):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=64)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    sentiment_score = probabilities[0][1].item()  # Probability of positive sentiment\n",
        "\n",
        "    if sentiment_score > 0.6:\n",
        "        return \"Positive\"\n",
        "    elif sentiment_score < 0.4:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "def extract_keywords(query, num_keywords=5):\n",
        "    # Tokenize the query\n",
        "    tokens = word_tokenize(query.lower())\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and token.isalnum()]\n",
        "\n",
        "    # Get frequency distribution\n",
        "    fdist = FreqDist(tokens)\n",
        "\n",
        "    # Return the most common words\n",
        "    return [word for word, _ in fdist.most_common(num_keywords)]\n",
        "\n",
        "# Function to analyze a query\n",
        "def analyze_query(query):\n",
        "    sentiment = predict_sentiment(query)\n",
        "    keywords = extract_keywords(query)\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"sentiment\": sentiment,\n",
        "        \"keywords\": keywords\n",
        "    }"
      ],
      "metadata": {
        "id": "zHKeUUxyDgrH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Agent_escalation.csv')\n",
        "\n",
        "# Analyze each query in the dataset\n",
        "results = []\n",
        "for query in df['Query']:\n",
        "    results.append(analyze_query(query))\n",
        "\n",
        "# Create a new dataframe with the results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Merge with the original dataset\n",
        "final_df = pd.concat([df, results_df[['sentiment', 'keywords']]], axis=1)\n",
        "\n",
        "# Display the first few rows of the final dataframe\n",
        "print(final_df.head())\n",
        "\n",
        "# Save the results\n",
        "final_df.to_csv('sentimental_analyzed_dataset.csv', index=False)\n",
        "print(\"Analysis complete. Results saved to 'sentimental_analyzed_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih4c8Vc-Dpig",
        "outputId": "613b5bdd-ac72-414d-d1f1-f76bc8371625"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Query            Escalation  \\\n",
            "0            Can I set an expiry date for my survey?  No escalation needed   \n",
            "1  Could you explain how to how do i connect my g...     Escalation needed   \n",
            "2  I need assistance with account management: wha...     Escalation needed   \n",
            "3  I'm having trouble with pricing and billing: i...     Escalation needed   \n",
            "4  Can you help me understand how to the survey i...     Escalation needed   \n",
            "\n",
            "  Sentiment             Category sentiment  \\\n",
            "0  Positive      Data Collection  Negative   \n",
            "1   Neutral         Integrations  Positive   \n",
            "2  Positive   Account Management  Positive   \n",
            "3  Negative  Pricing and Billing  Positive   \n",
            "4   Neutral     Technical Issues  Positive   \n",
            "\n",
            "                                           keywords  \n",
            "0                       [set, expiry, date, survey]  \n",
            "1      [could, explain, connect, google, analytics]  \n",
            "2  [need, assistance, account, management, process]  \n",
            "3     [billing, trouble, pricing, discount, annual]  \n",
            "4       [help, understand, survey, loading, slowly]  \n",
            "Analysis complete. Results saved to 'sentimental_analyzed_dataset.csv'\n"
          ]
        }
      ]
    }
  ]
}